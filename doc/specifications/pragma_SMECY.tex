% Deal with strides ?


\documentclass[a4paper]{article}
\usepackage[latin9]{inputenc}
\usepackage{a4wide}
\usepackage{alltt,url}
\usepackage{todonotes}
\usepackage{listings}


\lstset{language=C, numbers=left, numberfirstline=false, stepnumber=5,
  basicstyle=\small, keywordstyle=\bf}

% For various symbols:
\let\OldRightarrow=\Rightarrow
\RequirePackage{marvosym}
\let\MarvosymRightarrow=\Rightarrow
\let\Rightarrow=\OldRightarrow
\RequirePackage{wasysym}
% Deal with conflicts between ifsym and marvosym by renaming conflicting
% symbols:
\let\MarvosymLightning=\Lightning
\let\Lightning=\UnTrucIndefini
\let\MarvosymLetter=\Letter
\let\Letter=\UnTrucIndefini
\let\MarvosymSun=\Sun
\let\Sun=\UnTrucIndefini
\RequirePackage[weather,misc,alpine,clock]{ifsym}

\begin{document}

\title{SME-C v0.5\\
  ---\\
  C99 with pragma and API for parallel execution, streaming, processor
  mapping and
  communication generation\\
  ---\\
  SMECY Artemis European Project}

\author{Rémi~\textsc{Barrère}~(\url{Remi.Barrere@thalesgroup.com}) \and
  Marcel~\textsc{Beemster}~(\url{marcel@ace.nl}) \and
  Ronan~\textsc{Keryell}~(\url{Ronan.Keryell@silkan.com})}

\maketitle

\tableofcontents{}


\section{Introduction}
\label{sec:introduction}

In the SMECY project we want to use C source code as a portable
intermediate representation (IR) between tools from high-level tools down
to lower-level tools because of its good trade-off between expressiveness
and readability, without compromising portability.

The targets envisioned in SMECY are heterogeneous multicore systems with
shared memory or not, with various hardware accelerators, such as ASIC,
ASIP, FPGA, GPU, specialized vector processors, partially reconfigurable
accelerators...

Unfortunately, since it is undecidable to get high-level properties from
such programs, we use decorations to help tools to understand program
behaviour and generate codes for some hardware targets. We try to keep
clear decorations, easy to understand, so that SMECY C (summarized as
SME-C in the following but also referred as IR-1 in the project) can also
used as a programming language.

A SMECY program contains various functions that may be executed on various
processors, accelerators, GPU... that may consume and produce data from
different physical memory spaces.

Since we want to express also performance on given platforms, we keep the
opportunity to have platform-specific pragma and API or specialized
intrinsic types and functions, for example to express use of special
hardware accelerator functions or operations.

The hardware specific pragma and intrinsics are to be defined between
software and hardware partners involved in various use cases. But it may
not possible to address all the programming models and platforms
envisioned in the project.

The description of a reference compiler, \texttt{smecc}, is given in a
companion report, ``Some implementation details from the \texttt{smecc}
compiler''. Several tools producing or consuming SME-C have been developed
in the SMECY project.


\subsection{SMECY programming model}
\label{sec:programming-models}

The programming model is based on C processes, with a virtual shared
memory and threads \emph{à la} OpenMP. Since we may have quite
asynchronous processes in a real application description or at the
back-end level in the execution model, we can cope indeed with different C
processes communicating with an API.

We add mapping information stating on which hardware part a function is to
be placed and run.

The programming model exposed in the following is based on an OpenMP SMP
model because of its (rather) simple readability, elegance, old background
and wide acceptance. We make the hypothesis that a SMECY program is a
correct OpenMP program that can be executed in sequential with a C
OpenMP-free compiler (just by ignoring OpenMP \verb|#pragma|) and in
parallel on a SMP target (such an ARM or $x$86 machine) by using an OpenMP
compiler \emph{with the same semantics}. Since we use C (by opposition to
a DSL) as an internal representation, we choose this behaviour to stick to
standard behaviour as much as possible. This is known as the sequential
equivalence. Since we can cope different results for performance reasons
from executing in parallel non associative floating point operations, we
deal with only \emph{weak} sequential equivalence instead of
\emph{strong} sequential equivalence.

Of course, this model is incompatible with a real hardware target
envisioned in SMECY, so we need to add hints in the code explaining memory
dependencies at the function call levels. Since it is quite difficult to
describe general dependencies, we approximate memory dependencies with
rectangles (and more generally hyperparallelepipede in any dimension) that
can be read, written or both. We think these abstractions are good
trade-offs between expressiveness (and what a programmer can endure...)
and hardware capabilities. Even if there is some similitude with HPF (High
Performance Fortran) or XMP pragmas, we do not deal with
strides\footnote{Indeed, by using some higher dimensional arrays than the
  arrays used in the application, you can express them... So may be we
  should allow to express them in the syntax?}.

With this information, the tools can guess the communication to generate
between the different functions and memory spaces to emulate the global
OpenMP memory semantics.

The neat side effect is that we have the same global program executed on
all the platforms (sequential, real OpenMP and SMECY) with the same
semantics and we can see the sequential version as a functional simulator
of the SMECY application and the real OpenMP version as a parallelized
quicker version of this simulator.

It is also easy to debug the application, but also all the SMECY tools
used or developed in the project.

To be able to address real hardware from the C level with special needs:
\begin{itemize}
\item to specify hardware register names;
\item define input/output routines specifically but in portable way;
\item define fixed point arithmetic computations with a given precision;
\item specific data size;
\item accumulator register (DSP...);
\item different memory spaces that can be chosen specifically to optimize
  storage and speed (DSP, hardware accelerators with scratch pad
  memory...);
\item saturated arithmetic.
\end{itemize}
For all these we rely on the TR 18037 Embedded C standard, supported for
example by ACE tools.

To describe different processes communicating together in an asynchronous
way, we do not have anymore a sequential equivalence and then do not use
pragma to express this. So we use a simple communication, synchronization
and threading API. Since we target embedded systems with a light efficient
implementation, we can rely on such standard API as the ones of the
MultiCore Association: MCAPI (communication), MRAPI (synchronization) and
MTAPI (threading).

As modern programs need a clear documentation, such as with Doxygen
marking style providing meta information on different elements of the
program, we can use this (hopefully correct) information to help the
compiling process itself.

Since tools are to be oriented for a specific target, taking into account
various hardware and compilation parameters that are to be kept
orthogonally to application sources, those parameters are kept aside in
some description files that flow between tools. These files may be
represented with an XML syntax (using a SMECY naming space) or by even
simpler format (JASON, YAML...).


\subsection{SME-C Streaming Model}
\label{sec:sme-c-streaming}

This section describes the state of the newly developed
Streaming Annotation to C for use in SMECY. This is a work in
progress, so many imperfections still need to be fixed and
many extensions are both desireable and possible.

\subsubsection{Background}
\label{sec:background}

In several of the SMECY applications, is appears to be
a suitable parallel computation model to exploit application
parallelism. This is the case in particular for two of the
Use-Case-A applications, the M5 protocol analyser and the OFDM
application.

Streaming has the advantage that it fits well to parallelizing
applications that process data in a pipelined fashion, while
there may still be strong data dependencies that require
data to be processed sequentially at specific points in
the pipeline.  This is opposed to a data-parallel model,
where such dependencies do not exist.

Streaming can exploit both a coarse-grained level of
parallelism and parallelism at a fine-grained level. At
the fine-grained level, the overhead of passing data
between processing nodes in the pipeline must of course be
minimized. For fine-grained parallelism, this may require
hardware support. To achieve good load balancing, it is
important that the processing nodes have a comparable grain
size. If one node required much more processing than the
others, it becomes the bottleneck and no parallelism can
be exploited.

Streaming has the advantage of data locality. Data is passed
around in the distributed point-to-point network. Such networks
can be implemented far more efficiently than, for example,
a shared memory connection between the processing nodes.


\subsubsection{Goals}
\label{sec:goals}

\begin{enumerate}
\item The SME-C streaming model is an annotation on top of
  a valid sequential program. Thus, the program should also
  work when the streaming annotations are ignored. This eases
  program development because it allows the validation of the
  program in an sequential environment.
\item In principle, a streaming program can also be written using
  OpenMP, but it requires the explicit coding of the communication
  between nodes. In the SME-C streaming model, the communication
  is derived from the program source and generated by the compiler.
  This is very important for the parallel performance tuning of
  the application because it allows to experiment with different
  load partitioning without having to re-program process
  communication.
\item The SME-C streaming model is mapped onto a few basic
  parallel machine primitives for process creation and
  communication. The eases the task of retargeting to different
  target architectures, with shared or distributed memory between
  the nodes.
\end{enumerate}


\subsubsection{Status as of June 2011}
\label{sec:status-as-june}

ACE has currently implemented a source-to-source compiler
that accepts C programs with the streaming annotation and
produces a partitioned program with separate processes
(nodes) for each of the nodes in the stream. In addition,
it implements the communication links between the nodes.

The generated code includes library calls to implement the
low-level tasks of process creation and synchronization. This
small library of about 5 calls is currently implemented on top
of (shared memory) POSIX pthreads. It is not hard to retarget
this library to different underlying run-time systems.

To be used, the streaming model requires a part of the target
application to be rewritten into a particular form, using a
while loop and the SME-C stream annotations. Only this part
needs to be passed through the source-to-source compiler. Hence,
large parts of the application remain unmodified and do not need
to be processed by the stream compiler.

Stream termination is currently not handled well. Stream
termination has to be mapped from a sequential to a distributed
decision process and the design and implementation of that is
still to be done.


\subsubsection{Future Extensions (not Implementation Related)}
\label{sec:future-extens-not}

The highest priority for extension is to provide a mechanism for
stream termination. The challenge here is to make the mechanism
such that it still allows a natural programming style under
sequential program interpretation.

To facilitate additional parallel performance tuning, a
mechanism must be design to allow node replication. It would
allow for a single node (that turns out to be a bottleneck) to
be replicated into multiple nodes that run on multiple
processors. Obviously this complicates the generated
communication primitives.

Instead of generating communication primitives, the compiler
can also limit itself to only partitioning and generate a
communication graph for subsequent processing by tools such
as SPEAR and BIPS in the SMECY project.

An extension is needed to pass (fixed) parameters and
initial values into the streaming nodes that do not turn
into communication.

For TVN's H264 application, certain compute intensive loops
rely on array processing. Although there is parallelism
in these loops, they cannot be easily mapped to a fully
data-parallel implementation because of data dependencies. Given
the nature of these data dependencies, it seems to be possible
to transform them into a stream-processing model.


\subsection{Reference documents}
\label{sec:reference-documents}

\todo{To update, with OpenMP 4, XMP, C11, C++11..., OpenACC, OpenHMPP...}
Besides the SMECY documentation, the reader should be knowledgeable of
some work of the ISO/IEC JTC1/SC22/WG14 committee on the C language
standard:
\begin{itemize}
\item ISO/IEC 9899 - Programming languages - C (Technical Corrigendum 3
  Cor. 3:2007(E))
  \url{http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf}
\item TR 18037: Embedded C
  \url{http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1169.pdf}
\item Future C1X standard
  \url{http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1548.pdf}
\end{itemize}
and other standards such as
\begin{itemize}
\item MCA (MultiCore Association) API: MCAPI, MRAPI \& MTAPI,
  \url{www.multicore-association.org}
\item HPF (High Performance Fortran)
  \url{http://hpff.rice.edu/versions/hpf2}
\end{itemize}


\section{Intermediate representation use cases}
\label{sec:interm-repr-use}

\todo{Insert here the SMECY use-cases to develop generic use-cases}


\subsection{Direct programming}
\label{sec:direct-programming}

A programmer can program her application directly in SME-C with OpenMP
and SMECY-specific pragma and API to target a SMECY platform.

It can be at rather high-level, by using only high-level pragma, or rather
at a lower level, by using different communicating processes with the API
and even specialized API and pragma for specific hardware.

A process written in C code with pragma and API can express a global host
controlling process of an application or a local program in a specialized
processor. And we may have many of such processes to express different
producer and consumer Kahn processes interacting through a NoC in an
asynchronous way.


\subsection{System high-level synthesis}
\label{sec:high-level-synthesis}

A compiler can take a sequential plain C, MATLAB, Scilab, NumPy or another
language code, analyze and parallelize the code by adding automatically
parallel and mapping pragma. This can be seen as a high-level synthesis at
system level.

A tool such as Par4All can do these kinds of transformation.


\subsection{Hardware high-level synthesis}
\label{sec:hardware-high-level}

A compiler can take a program with SMECY pragma and compile any call with
a mapping of a given kind into some hardware configuration or program to
be executed instead of the function and an API call to use this
hardware part from the host program.

Since the pragma are designed to be concretely compilable, such a tool
should be easy to do with a simple compilation framework, such as ROSE
Compiler.

The SMECY API and intrinsics are chosen to be mapped quite
straightforwardly to real hardware functions by the back-end.


\section{Exemples}
\label{sec:exemples}

\subsection{Program with contiguous memory transfers}
\label{sec:progr-with-cont}

During C memory transfer, if we work on arrays with the last dimension
taken as a whole, the memory is contiguous and the programs often work
even there are some aliasing such as using a 2D array zone as a linearized
1D vector.

The following program exposes this kind of code where some work sharing is
done by contiguous memory blocks.

\lstinputlisting{examples/pragma_example.c}


\subsection{Program with non-contiguous memory transfers}
\label{sec:program-with-non}

In the following example, we apply different computations on square pieces
of the image, that do not have contiguous representation in memory. That
is why we need to express restrictions on the use of the whole array.

\lstinputlisting{examples/2D_example.c}


\subsection{Pipelined example}
\label{sec:pipelined-example}

The example shows a produced/consumer program. At every
communication step, a full array of 128 integers is passed from
the 'Producer' to the 'Consumer'. The streaming compiler finds
out the sizes of the communication buffers from the program.

\begin{figure}
  \lstinputlisting{examples/pipeline_example.c}
  \caption{Example of pipelined streamed loop.}
\label{fig:pipelined_example}
\end{figure}


\subsection{Remapping example}
\label{sec:remapping-example}

Some information can be in a given layout but needed in another layout to
be used by a specific hardware accelerator.

\lstinputlisting{examples/remapping_example.c}


\section{Description of high level process structure}
\label{sec:descr-high-level}

Here should be described the metadata on the process organization.

\todo{It should be able to describe process instance, interconnection...}


\section{SMECY embedded C language}
\label{sec:embedded-c}

We take as input C99 (ISO/IEC 9899:2007) language with extensions for
embedded systems (TR 18037).

Refer to these documents for more information.

\todo{comment the following}
\begin{verbatim}
__thread
Thread-Local Storage
_Thread_local
Doc. No.:   WG14/N1364
Date:   2008-11-11
Reply to:   Clark Nelson

http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1364.htm

C++
ISO/IEC JTC1 SC22 WG21 N2659 = 08-0169 - 2008-06-11 proposal
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2659.htm



http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1351.pdf
WG14 N1351
C Language support for multiprocessor application
environments.
Walter Banks
Byte Craft Limited
Canada
February 2009


ISO/IEC JTC1 SC22 WG14 N1275
Date: 2007-10-20
Reference number of document:
ISO/IEC TR 18037
Committee identification: ISO/IEC JTC1 SC22 WG14
SC22 Secretariat: ANSI
http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1275.pdf

WG14 N1386
Additions to ISO/IEC TR 18037 to support named execution
space.
Walter Banks
Byte Craft Limited
Canada
April 2009
Named execution addition to IEC/ISO 18037
http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1386.pdf
\end{verbatim}


\section{Description of the SMECY directives}
\label{sec:description}

The generic format of SMECY code decorations are language dependent,
because if here we describe a SMECY IR implementation based on C, it is
indeed more general.

\begin{itemize}
\item In C/C++:
\begin{alltt}
#pragma smecy \emph{clause[[,]clause]... newline}
\end{alltt}
  We can use \verb|\| at the end of line for continuation information.
\item In Fortran:
\begin{alltt}
!$smecy \emph{clause[[,]clause]... newline}
\end{alltt}
  Use \verb|&| at the end of line for continuation information.
\item In other languages: use \verb|#pragma| equivalent, if not available,
  use comments \emph{à la} Fortran. For example in Python:
\begin{alltt}
#$smecy \emph{clause[[,]clause]... newline}
\end{alltt}
  Use also \verb|&| at the end of line for continuation information
\end{itemize}

In implementations that support a preprocessor, the \verb|_SMECY| macro
name is defined to have the decimal value \emph{yyyymm} where \emph{yyyy}
and \emph{mm} are the year and month designations of the version of the
SMECY API that the implementation supports.  If this macro is the subject
of a \verb|#define| or a \verb|#undef| preprocessing directive, the
behavior is unspecified.



\subsection{OpenMP support}
\label{sec:openmp-support}

SMECY is based on OpenMP 3.1. Since a SMECY platform is made at least form
a (SMP) control processor, any OpenMP compliant program can run on it
anyway. The SMECY tools can use more or less information from available
OpenMP decorations available in the code.

The on-coming version 4 dealing more with SIMD instruction and
heterogeneous computing seems promising as a starting point for a next
version of SME-C.


\subsection{Mapping on hardware}
\label{sec:mapping-hardware}

The mapping of a function call on a specific piece of hardware can be
specified with
\begin{alltt}
#pragma smecy map(\emph{hardware[}, \emph{unit][, unit]...})
  some_function_call(...);
\end{alltt}

\begin{itemize}
\item \texttt{\emph{hardware}} is a symbol representing a hardware
  component of a given target such as \texttt{CPU}, \texttt{GPP},
  \texttt{GPU}, \texttt{PE}... They are target specific.
\item \texttt{\emph{unit}} are optional multidimensional instance number
  for a specific hardware part. This is typically an integer starting a 0
  or for ST THORM 2 integers, the first one is the cluster number and the
  second one is the processor element number inside the cluster. This
  hardware number can be an expression of the environment to be able to
  have a loop managing different accelerators.
\end{itemize}

We can add an \texttt{if(\emph{scalar-expression})} to predicate hardware
launching according some run-time expression to choose between hardware or
local software execution, as in OpenMP with the same syntax. The idea is
to be able to do a software execution if the data to process is too small
compared to the latency of an hardware accelerator.

Recursion is not supported on hardware-mapped functions. If there are
functions called from hardware-mapped functions, they will be
automatically inlined (so no recursion allowed in them either). If a
function is mapped to a more programmable hardware (GPP), recursions in
these called functions should be allowed.

By default, call to hardware accelerators are synchronous, so you may
launch the call into an OpenMP thread or into another MCA API process.
But simpler way is to use the \texttt{async} keyword to launch in an
asynchronous way, such as:
\begin{alltt}
#pragma smecy map(...) async
\end{alltt}

But the it may be useful to way later for the production of an accelerator
to be ready. This is done with the \texttt{wait} pragma such as in:
\begin{alltt}
#pragma smecy wait(PE,2)
\end{alltt}


\subsection{Producer/consumer information}
\label{sec:prod-inform}

To generate hardware communications where there is only a function call,
the compiler need to figure out what is the memory zone used to execute
the function and then what memory zone in written by the function
\emph{and} that will be used later in the program\footnote{If a function
  produces something not used later, it is useless to get it back.}. From
these information, copy-in and copy-out operations can be generated.

\subsubsection{Function arguments}
\label{sec:function-arguments}


\begin{alltt}
#pragma smecy arg(\emph{arg_id}, \emph{arg_clause[, arg_clause]...})
  some_function_call(...);
\end{alltt}


\begin{description}
\item[Direction directive] defines how the data flows between the caller
  and the function:
  \begin{itemize}
  \item[\texttt{in}:] the argument is used by the function;
  \item[\texttt{out}:] the argument is used by the function;
  \item[\texttt{inout}:] the argument is used and produced by the function;
  \item[\texttt{unused}:] the argument is not used and produced by the
    function.
  \end{itemize}

\item[Argument layout] specifies how the argument is used in the
  function with:
  \begin{itemize}
  \item an optional \texttt{\emph{array\_size\_descriptor}} such as
    \verb|[n][m]| expressing that the data is used from the callee point
    of view as such an array starting at the address given in
    parameter. If not specified, all the caller argument is used;
  \item an optional \texttt{/\emph{array\_range\_descriptor}}restriction
    such as \verb|/[n:m][2][3:7]| expressing that the data is used from the
    callee point of view as an array with only this element ranges
    used. If not specified, all the array is used according to its size
    specified or not. If only some ranges are lacking, all the matching
    dimension is used. For example \verb|/[4][]| matches the column 4 of
    an array.
  \end{itemize}
  The more precise this description is and the less data transfers occur.
\end{description}

If the argument usage is independent from the call site they can be
specified only at the function definition level instead of at each call
site..


\subsubsection{Global variables}
\label{sec:global-variables}


Right now we do not deal with sharing information through global
variables, because it is more difficult to track. Only function parameters
are used to exchange information.

But we can imagine to map global variables with this clause:
\begin{alltt}
#pragma smecy global_var(var, \emph{arg_clause[, arg_clause]...})
  some_function_call(...);
\end{alltt}


\subsection{Stream programming}
\label{sec:stream-programming}

It is possible to stream a \texttt{while} loop in several pipeline stages
that execute in parallel and pass information between stages/

The two pragmas used here are:
\begin{description}
\item[\texttt{\#pragma smecy stream\_loop}:] this indicated the following
  \texttt{while} loop must be turned into a stream of processes;

\item[\texttt{\#pragma smecy stage}:] this acts as a separator between
  groups of statements and define the boundary of pipeline stages. Only
  data passing over these separators is turned into
  communication.\footnote{It used to be \texttt{\#pragma smecy
      stream\_node($n$)} as an instruction to define both a stage node and
    a way to name it for another later use by \textsc{ace}. But after
    København meeting, it appears it is better to use another way to label
    things only when needed. See \S~\ref{sec:labelling-statement}.} Note
  that the first stage pragma can be eluded since the begin of the loop
  body define a stage up to the next stage pragma.
\end{description}

You can refer to example shown on figure~\ref{fig:pipelined_example}.


\subsection{Labelling statement}
\label{sec:labelling-statement}

Since ACE mentioned an interest to name part of a program from other
external tools, such as to do some fine mapping, a labeling pragma has
been added to name\footnote{Should it be an atom, a string, a number?}
statements:
\begin{alltt}
#pragma smecy label(\emph{name})
  \emph{any_statement};
\end{alltt}


\subsection{Remapping specification}
\label{sec:remapp-spec}

\todo{To finish}

Since we always want a sequential equivalence, that means that the
sequential code representing the computation on an accelerator really
consume The easy

HPF



\subsection{Hardware specific pragma}
\label{sec:hardw-spec-pragma}

\todo{To be defined in collaboration with the various hardware
  suppliers of the project (ST P2012/STHORM, EdkDSP/ASVP...).}


\section{SMECY high-level APIs}
\label{sec:smecy-api}

\subsection{OpenMP}
\label{sec:openmp}

Since we support OpenMP pragma, we also support OpenMP API that allows for
example:
\begin{itemize}
\item getting/setting the number of threads;
\item getting the number of available processors on the current domain;
\item manipulating locks.
\end{itemize}


\subsection{MultiCore Association APIs}
\label{sec:mult-assoc-apis}

Since in this project we deal with communicating processes, asynchronous
communications, synchronization, etc. we need an API to be able to
express them from inside the processes. We rely on a standard API instead
of reinventing on again. The MultiCore Association designed some APIs
specially targeted at low resource embedded systems, so we rely on the
MCAPI, MTAPI and MRAPI for low memory footprint light-weight
communications, threading and synchronization.

There is a free implementation based on POSIX so we can have a working
version on any decent operating system for testing the SME-C programs.
Since this is a reference implementation based on Linux \emph{pthreads},
it can also be used as an example to port to the various available
hardware.

During the SMECY project, ST \& CEA has phased out NPL, their own library
to program the STHORM, because it was equivalent to the MCA standard API.
So for a message passing interface API, the MCA APIs have to be used on
this platform.

Right now there are 3 different specifications we can use in the project.


\subsection{Multicore Communication API (MCAPI)}
\label{sec:mult-comm-api}

This is the main and first produced API by the MCA\footnote{Note that
  this MCAPI should not be confused with the MCA APIs, that are the APIs
  in general designed by the MultiCore Association, even if the WWW site
  and the documents of this association are not always very clear... This
  was confusing during the København meeting.} dealing with communications
between processes.

This standard define basically 3 kinds of communication channels:
\begin{itemize}
\item messages: connection-less datagrams, similar to UDP datagrams in
  IP networking;
\item packet channels: connection-oriented, unidirectional,
  FIFO packet streams;
\item scalar channel: connection-oriented, single-word, unidirectional,
  FIFO scalar streams.
\end{itemize}

A communication entity in MCAPI is a node, that can be gathered in
some domains to add hierarchy, and can represent a process on a processor
or a hardware accelerator for example.

Please refer to the ``Multicore Communications API (MCAPI) Specification
V2.015'' document for more information.


\subsubsection{MTAPI}
\label{sec:mtapi}

\todo{To complete}


\subsubsection{MRAPI}
\label{sec:mrapi}

\todo{To complete}


\subsection{NPL API}
\label{sec:npl-api}

NPL is the API defined to program ST P2012/STHORM in a native way. Since it is
rather at the same level of MCAPI/MRAPI/MTAPI, it should be easy to
implement one above the other. Since the MCA APIs are standard, we thing
that it is commercially interesting to provide a MCA APIs over NPL or
other to widen P2012/STHORM usage.

Indeed, in 10/2011 this API seems to have been phased out by ST \& CEA. So
this part is kept for it history interest and MCAPI is used in the SMECY
project as a lower intermediate representation, the IR-2.


\subsection{EdkDSP/ASVP API}
\label{sec:edkdsp-api}

\todo{Define here what is useful in the project.}


\subsection{OpenCL}
\label{sec:opencl}

Since ST P2012/STHORM can be programmed in OpenCL which is also a programming
API, a C process can use OpenCL orthogonally with other API. A kernel
launching is done by defining the kernel source, the memory zone to use
and to transfer and the different parameters of the kernel.

Refer to OpenCL documentation for more information.


\section{SMECY low level hardware API}
\label{sec:low-level-hardware}

To call real hardware accelerators, few C macros are needed to interface a
program running on some processor to a function running on another
processor or in some hardware accelerator.

Since the implementation may depend also on the processor calling the
macros (not the same IO bus will be used from an $x$86 or a DSP to call
the same operator), a global preprocessing symbol must be defined by the
compiler before using these macros, such as
\begin{lstlisting}
#define SMECY_LOCAL_PROC x86
\end{lstlisting}
or
\begin{lstlisting}
#define SMECY_LOCAL_PROC DSP
\end{lstlisting}

Few macros are necessary:
\begin{lstlisting}
/* Prepare a processing element to execute a function

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element

   pe is not a string because it is easy to make a string from it but not
   the opposite. The same for func
*/
#define SMECY_set(pe, instance, func) ...

/* Send a scalar argument to a function on a processing element

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function running on the processor element
   @param[in] arg is the argument instance to set
   @param type is the type of the scalar argument to send
   @param[in] val is the value of the argument to send
*/
#define SMECY_send_arg(pe, instance, func, arg, type, val) ...

/* Send a vector argument to a function on a processing element

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element
   @param[in] arg is the argument instance to set
   @param type is the type of the vector element to send
   @param[in] addr is the starting address of the vector to read from
              caller memory
   @param[in] size is the length of the vector
*/
#define SMECY_send_arg_vector(pe, instance, func, arg, type, addr, size) ...

/* Launch the hardware function or remote program using previously loaded
   arguments

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element

   A kernel can be launched several times without having to set/reset its function.
*/
#define SMECY_launch(pe, instance, func) ...

/* Get the return value of a function on a processing element

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element
   @param type is the type of the scalar argument to send
   @return the value computed by the function
*/
#define SMECY_get_return(pe, instance, func, type) ...

/* Get a vector value computed by a function on a processing element

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element
   @param[in] arg is the argument instance to retrieve
   @param type is the type of the vector element
   @param[out] addr is the starting address of the vector to write in
               caller memory
   @param[in] size is the length of the vector
*/
#define SMECY_get_arg_vector(pe, instance, func, arg, type, addr, size) ...

/* Prepare the retrieving of a vector value that will be computed by a
   function on a processing element.

   Typically, it can be used to allocate software or hardware resources
   for the later SMECY_get_arg_vector().

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to load on the processor element
   @param[in] arg is the argument instance to retrieve
   @param type is the type of the vector element
   @param[out] addr is the starting address of the vector to write in
               caller memory
   @param[in] size is the length of the vector
*/
#define SMECY_future_get_arg_vector(pe, instance, func, arg, type, addr, size) ...

/* Reset a processing element to execute a function

   @param pe is the symbol of a processing element, such as GPP, DSP, PE...
   @param[in] instance is the instance number of the processor element to use
   @param func is the function to unload from the processor element

   This is used for example to remove consuming resources to decrease
   power. Giving here the function name may be useful for weird case to
   avoid having short-circuit between CLB in a FPGA during unconfiguring stuff
*/
#define SMECY_reset(pe, instance, func) ...
\end{lstlisting}
There is also a macro for an asynchronous call and to wait for completion.


\section{Compilation}
\label{sec:compilation}

\subsection{Example of OpenCL mapping}
\label{sec:example-opencl-mapp}

A typical mapping of the SMECY low level hardware API shown on
\S~\ref{sec:low-level-hardware} would be organized as follows:
\begin{itemize}
\item \verb|SMECY_set(PE, proc & 7, invert_vector)|:\\
  \texttt{clCreateProgramFromSource()} +
  \texttt{clBuildProgramExecutable()} + \texttt{clCreateKernel()}
\item \verb|SMECY_send_arg(PE, proc & 7, invert_vector, 1, int, LINE_SIZE)|:\\
  \texttt{clSetKernelArg()}
\item \verb|SMECY_send_arg_vector(PE, proc & 7, invert_vector, 2, int,...)|:\\
  \texttt{clCreateBuffer()} + \texttt{clSetKernelArg()} (+
  \texttt{clEnqueueWriteBuffer()})
\item \verb|SMECY_launch(PE, 0, invert_vector)|:\\
  \texttt{clExecuteKernel()}
\item \verb|SMECY_get_arg_vector(PE, proc & 7, invert_vector, 3, ...)|:\\
  \texttt{clEnqueueReadBuffer()}
\end{itemize}


\subsection{Example of EdkDSP mapping}
\label{sec:example-edkdsp-mapp}


\subsection{OpenMP support}
\label{sec:openmp-support-1}

From the programmer point of view it may be equivalent to have
\begin{itemize}
\item an OpenMP compiler generating SMECY API code such as the parallelism
  between SMECY target accelerators is run by OpenMP threads dealing each
  one with an hardware resource sequentially in a synchronous way;
\item or a SMECY compiler understanding the OpenMP syntax and generating
  directly some parallel execution of SMECY accelerators in an
  asynchronous way.
\end{itemize}


\subsection{Doxygen qualifier}
\label{sec:doxygen-qualifier}

In the Doxygen documentation mark-up language used in comments to detail
various entities of a program, there are information such as \texttt{in},
\texttt{out} or \texttt{inout} qualifier on function parameters that can
be used to generate the right communication with some hardware
accelerators.


\subsection{C qualifier}
\label{sec:c-qualifier}

Qualifiers such as \texttt{const} attribute qualifier, address space
names, register names, accumulator, saturation, etc. are used to generate
the right target function or instruction.


\subsection{Generating communications from pragma}
\label{sec:pragma}

Of course the pragma information is heavily used in the compilation
process.

For example to generate correct communication, the mapping information is
used, and from the used/defined information plus optional remapping
information, a real communication with an API is used.

\begin{lstlisting}
void
invert_vector(int line_size,
          int input_line[line_size],
          int output_line[line_size]) {
  for(int i = 0; i < line_size; i++)
    output_line[i] = 500 - input_line[i];
}
  [...]
  int image[HEIGHT][WIDTH];
  [...]
#pragma smecy map(PE, proc & 7)         \
              arg(2, in, [1][LINE_SIZE])    \
              arg(3, out, [1][LINE_SIZE])
    // Invert an horizontal line:
    invert_vector(LINE_SIZE,
          &image[HEIGHT - 20 - proc][WIDTH/2 + 2*proc],
          &image[HEIGHT - 20 - proc][WIDTH/2 + 2*proc]);
\end{lstlisting}
can be compiled into
\begin{lstlisting}
  int image[HEIGHT][WIDTH];
  /* First prepare the PE #(proc & 7) hardware to execute invert_vector.
     That may be used to load some program or microcode, reconfigure a
     FPGA, load/compile an OpenCL kernel... */
  SMECY_set(PE, proc & 7, invert_vector);
  /* Send the WIDTH integer as arg 1 on invert_vector hardware function on
     PE #(proc & 7): */
  SMECY_send_arg(PE, proc & 7, invert_vector, 1, int, LINE_SIZE);
  /* Send a vector of int of size LINE_SIZE as arg 2 on invert_vector
     hardware function on PE #(proc & 7): */
  SMECY_send_arg_vector(PE, proc & 7, invert_vector, 2, int,
                        &image[HEIGHT - 20 - proc][WIDTH/2 + 2*proc], LINE_SIZE);
  // Launch the hardware function or remote program:
  SMECY_launch(PE, 0, invert_vector);
  /* Get a vector of int of size LINE_SIZE as arg 3 on invert_vector
     hardware function on PE #(proc & 7): */
  SMECY_get_arg_vector(PE, proc & 7, invert_vector, 3, &image[HEIGHT - 20 - proc]
                                                             [WIDTH/2 + 2*proc],
                       LINE_SIZE);
\end{lstlisting}
with low level macros described in \S~\ref{sec:low-level-hardware}.

\lstinline|invert_vector()| is either an already implemented function in a
hardware library, or it is compiled by a target specific compiler with
some callable interface.

For more complex calls needing remapping, such as:
\begin{lstlisting}
    int input_line[LINE_SIZE];
    int output_line[LINE_SIZE];
    /* We need to remap data in the good shape. The compiler should use
       the remapping information to generate DMA transfer for example and
       remove input_line array */
    SMECY_remap_int2D_to_int1D(HEIGHT, WIDTH, HEIGHT/3, 30 + 20*proc,
                   LINE_SIZE, 1, image,
                   LINE_SIZE, input_line);
    // Each iteration is on a different PE in parallel:
#pragma smecy map(PE, proc) arg(2, in, [LINE_SIZE]) arg(3, out, [LINE_SIZE])
    invert_vector(LINE_SIZE, input_line, output_line);
    SMECY_remap_int1D_to_int2D(LINE_SIZE, output_line,
                   HEIGHT, WIDTH, HEIGHT/3, 30 + 20*proc,
                   LINE_SIZE, 1, image);
\end{lstlisting}
is compiled by using other hardware interfaces involving more complex DMA:
\begin{lstlisting}
  // May not be useful if this function is already set:
  SMECY_set(PE, proc & 7, invert_vector);
  /* Send the WIDTH integer as arg 1 on invert_vector hardware function on
     PE #(proc & 7): */
  SMECY_send_arg(PE, proc & 7, invert_vector, 1, int, LINE_SIZE);
  /* Send a vector of int of size LINE_SIZE as arg 2 on invert_vector
     hardware function on PE #(proc & 7) but read as a part of a 2D array: */
  smecy_send_arg_int_DMA_2D_PE_0_invert_vector(3, &image[HEIGHT - 20 - proc]
                                                        [WIDTH/2 + 2*proc],
                                               HEIGHT, WIDTH, HEIGHT/3, 30 + 20*proc,
                                               LINE_SIZE, 1);
  SMECY_send_arg_DMA_2D_to_1D(PE, proc & 7, invert_vector, 2, int,
                              &image[HEIGHT - 20 - proc][WIDTH/2 + 2*proc],
                              HEIGHT, WIDTH, HEIGHT/3, 30 + 20*proc,
                              LINE_SIZE, 1);
  // Launch the hardware function or remote program:
  SMECY_launch(PE, 0, invert_vector);
  SMECY_get_arg_DMA_1D_to_2D(PE, proc & 7, invert_vector, 3, int,
                             &image[HEIGHT - 20 - proc][WIDTH/2 + 2*proc],
                             HEIGHT, WIDTH, HEIGHT/3, 30 + 20*proc,
                             LINE_SIZE, 1);
\end{lstlisting}


\subsection{Compilation for streaming computing}
\label{sec:comp-stre-comp}

If we come back on the example shown in \S~\ref{sec:pipelined-example} on
page~\pageref{sec:pipelined-example}, this program is given to the
source-to-source stream compiler that may generate the following output
(only partially shown, the type definitions are missing):
\begin{lstlisting}
/* Definition of procedures */
int main(void)
{
    typ_7 data_buffer;
    typ_21 data12Link;
    data12Link = pth_CreateDbLink(512);
    pth_CreateProcess((&__Node1), data12Link);
    pth_CreateProcess((&__Node2), data12Link);
    pause();
    return 0;
}

static void __outlinedproc2(typ_9 data_buffer)
{
    Consume(((typ_4)data_buffer));
}

static void __outlinedproc1(typ_9 data_buffer)
{
    Produce(((typ_4)data_buffer));
}

static void __Node1(typ_21 data12Link)
{
    typ_9 data_bufferOut;
    typ_4 tmp0;
    typ_4 tmp1;
    tmp0 = DbLinkGetInitBuff(data12Link);
    data_bufferOut = ((typ_9)tmp0);
    while(1){
        __outlinedproc1(data_bufferOut);
        tmp1 = DbLinkPutData(data12Link);
        data_bufferOut = ((typ_9)tmp1);
    }
}

static void __Node2(typ_21 data12Link)
{
    typ_9 data_bufferIn;
    typ_4 tmp0;
    while(1){
        tmp0 = DbLinkGetData(data12Link);
        data_bufferIn = ((typ_9)tmp0);
        __outlinedproc2(data_bufferIn);
    }
}
\end{lstlisting}
The last two functions are \verb|__Node1()| and \verb|__Node2()|. These
are the functions that run in the two processes. These two functions are
the wrappers around the user code, which is embedded in the two
\verb|__oulined...| functions. These wrappers take care of the
data communications. For every communication channel, they manage a
double-buffered scheme that minimizes the amount of copying.

In more realistic settings than this simple send/receive scheme,
the wrapper function become quickly more complex and non-trivial
to maintain manually.

The generated code contains calls to the following communication
library:
\begin{lstlisting}
/*
 * Create a double buffered communication link,
 * with each buffer the given size in bytes */
DbLink createDbLink( int size ) ;
/*
 * Get a pointer to a free output buffer from the
 * link. The pointer must be given back in the
 * call to DbLinkPutData */
void *DbLinkGetInitBuf( DbLink outputLink ) ;
/*
 * Get a pointer to data out of the link. This
 * is a read action of the link. The data pointed
 * to is valid until the next read. */
void *DbLinkGetData( DbLink inputLink ) ;
/*
 * Output the data pointed to over the link. The
 * pointer must have been previously obtained from
 * the link. */
data_bufferOut = DbLinkPutData( data_bufferOut ) ;
\end{lstlisting}

And finally there is also the process creation call:
\begin{lstlisting}
int pth_CreateProcess( int (*f)(), ... );
\end{lstlisting}
This library is not intended to become part of the SMECY-API described for
example in \S~\ref{sec:smecy-api} or \ref{sec:low-level-hardware}.
Instead, the library is intended for easy porting to SMECY-API, while
taking advantage of the most efficient communication implementation for
the specific target architecture. Currently, a \texttt{pthread}s-based
implementation exists.

This is just an example of a compilation path and it should be easy to
generate a C++ TBB (Thread Building Block) target code using for example
the \verb|tbb::pipeline|, a more low-level OpenMP runtime based on
\texttt{parallel sections} or \texttt{parallel task} pragma, or even an
MPI or MCA API for distributed memory execution.


\subsection{Geometric inference}
\label{sec:geometric-inference}

In the OpenMP SMP model, there is a global memory (well, with a weak
coherence model) that may not exist in the execution model of a given
target. For example, even if 2 hardware accelerators exchange information
through memory according to the high-level programming model, in the real
world we may have 2 processors communicating through message passing with
MCAPI on a NoC or 2 hardware accelerators connected through a pipeline.

To solve this issue, we use the OpenMP global memory like a scoreboard
memory that is used to symbolically relate all the data flows and
generates various communication schemes.

Since the memory dependencies are expresses by hyperparallelepipedes, we
can do some intersection analysis to compute if a communication is needed
or not between 2 devices of the target.


\end{document}


%%% Local Variables:
%%% mode: latex
%%% ispell-local-dictionary: "american"
%%% TeX-auto-untabify: t
%%% TeX-PDF-mode: t
%%% End:

% vim:spell spelllang=fr
